Name:         Jesse Isleib
EID:                 jsi234
CS Login:        isleibjs
Email:        jesse.isleib@gmail.com




Lecture 34
1) You can’t create an encoding that performs better (a lower entropy) than the language’s ideal entropy. Since entropy is “h” here, and “h” can only get bigger, the capacity of the channel can only get smaller.


2)  If the entropy is a lower number than the channel’s transmission rate ( C ), then you can for sure transmit at least 1 bit / second, with an encoding, even with noise on the channel.




Lecture 35
1) -(log(1/10))


2) Letters have different rates of occurrence, and those rates change a lot when you take the chances of digrams or trigrams (or more), meaning there is a lot of dependance.


3) 0 order models assume all symbols in the language are equally likely, while x-models show the likelihood of each element, with the element being made up of x symbols per element.




Lecture 36
1) Because of unknown factors. Maybe one way is how to test the varying probabilities being impossible (or not accurate), or maybe we don’t know if all the perspectives are the same, depending on the context 


2) An example would be: if you find the entropy of the english language from a book about the letter “z”. If the perspective then changes to someone reading shakespeare, the information content decreased by a lot.


3) Redundancy increases as the difference between entropy and actual transmission rates of an encoding increases.




Lecture 37
1) There are no letters, but if it is describing the location of treasure then it will most likely have letters, meaning it is not an offset (unless they were using ASCII back then), and is has many repeating letters, so there’s probably a substitution cipher.


2) Brute force could eventually decode the message anyways.


3) It obscures it.


4) Changes in the time it takes to encrypt different files may hint at how the encryption process works (timing attack).




Lecture 38
1) simply “P”


2) { { { P } K_E  } K_E } K_D


3) It gives hints at what kind of encryption is being used (method and complexity)


4) If you can recognize patterns in a language, you can potentially notice the results of encoding as well.




Lecture 39
1) if in order to break it, you must use brute force, and the range of possibilities is so large that it would simply take too long.


2) To try every combination of bits that applies equally to all plain&cipher texts.


3) They can spread out the original text into the cipher text, and make all the relevant symbols become different symbols with substitution. This combination is very strong (and fundamental) with encryption methods.


4) It depends on the complexity, but the best is a combination of both, rather than one alone.




Lecture 40
1) Monoalphabetic uses a constant cipher (shifting letters over by a certain number, Symbol 1 always turns into Symbol 2).
Polyalphabetic uses a cipher depending on where the symbol to be encrypted is in the message (“adding” two strings up, for example)


2) A 1-1 map which says what the plaintext symbols will become in the cyphertext.


3) The first of K symbols has K choices to map to. The next has (K-1) (the set of symbols excluding the first mapping). Already, we have K * (K-1) possible keys. This will continue until all mappings are assigned, or K* (K-1) * (K-2) * … * (2) * (1)


4) A number, which ranges from 1-(K-1) (if it wants to be useful…), representing the offset of the plain to cipher text.


5) 1-(k-1) unique keys. I guess you could also include 0, or “k” in that range, but it’d be pretty redundant of a key.


6) No, since learning about (1) the encryption style (simple substitution), (2) a set of cipher texts (and plaintexts, optionally), could
1) lead to a very simple brute force method of finding the key (literally only K-1 keys needed to be tested)
2) lead us to know that the encryption is based off simple substitution, thus (1)


7) “Subtracting” the encryption key from the cipher text (while the encryption is simply adding the encryption key to the plain text)




Lecture 41
1) If all we know is that it is substitution, then any set of three characters could be the cipher, each with 26 choices, which are repeatable.


2) both of the “y”s have the same plaintext character that they came from, so x could have come from 26 letters, and y could have come from any of the 25 not used by whatever x is.


3) As it is explicitly stated, yes: a “one-time pad”. However, it’s not so useful.




Lecture 42
1) Because learning anything about the encryption (the plaintext, ciphertext, or method of encryption) lower the possible keyset size (the key is truly random)


2) Otherwise, if there is any dependance on the language’s symbols (for example), then it’d not be perfect! (knowing the method and the plaintext allows for an easier cracking of the key)


3) If you encrypt something with one-time pad, then, since the key is random, the only way for anyone else to decrypt it is to have the key. If you can pass them the key in such a way that nobody can see, then why not send the message in that protected way?






Lecture 43
1) The original information is still there, just disoriented, so potentially easy to decipher.






Lecture 44
1) Symmetric; once you know the encryption key, you have the makings of the decryption key.


2) how we give keys to people = distribution; how we keep the keys safe = management


3) No, since the key for encryption is not the same as the key for decryption, thus the defining word “asymmetric” 


4) Depends too much on the context to compare the two. If you need people to send you encrypted messages that only you can decode, asymmetric is more necessary. If a key is known by only the people who send and receive messages, then perhaps symmetric keys are better.





Lecture 45
1) If an attacker messes up on ONE step of forming a decryption function, the whole message is liable to turn into gibberish. Another reason is that it is harder to damage the integrity of the file without seeming suspicious to people/entities that know of the encoding technique.

2) If the encryption is malleable, and the attacker has plaintexts and ciphertexts, they can both work to see how changing the plaintext changes the ciphertext and vice versa, making it a lot easier to find the encryption/decryption method(s).


3) It can allow two entities to hold only an encryption or decryption method, but have the ability to communicate through changing the plaintext and ciphertext (respectfully) with foreseeable results,






Lecture 46
1) -subBytes: map each element to another element on a lookup table (substitution)
-addRoundKey: encrypt each column by XORing it with a round key
-mixColumns: change the elements of each column by multiplying it (the column) with a set 4x4 matrix of integers


2) shiftRow: move rows left so that the first column has equal i and j values (i.e. every element in column 1 has the original matrix’s coordinates “0, 0”; “1, 1”; “2, 2”;. and so on. This is transposition, and is the only one that actually obfuscates the plaintext by actually moving the elements around.


3) One reason would be that the matrix used to decrypt is the inverse of the matrix in mixColumns, which requires a 4x4 matrix by 4x4 matrix multiplication, taking extra time.


4) The block is the size of the plaintext to be encrypted, and the rounds is the number of times the 4 steps mentioned in #1 and #2 are repeated.


5) The more rounds used, the more jumbled up the ciphertext will be.






Lecture 47
1) As with simple substitution, identical elements in the plaintext result in identical elements in the ciphertext.


2) Changing each successive block of plaintext. CBC XORs each plaintext block with the last one (given it is not the first) before encrypting.


3) Even this method can be eventually recognized as a pattern (such as if two identical ciphertexts exist, then their respective plaintexts must be equivalently related via XORing)


4) Key stream uses a one-time pad to make the bytes encrypted look random, while the keys are actually reproduceable. Block encryption has more to do with changing each block (by using the last one in the line of succession to change the current one) in whole before encrypting it.






Lecture 48
1) ...The private key. (this question was kind of easy, yeah?)


2) they are easy to compute, but are very hard to invert without extra knowledge (knowledge that the private key holder has)


3) Only 2N codes are needed (for RSA), N being the number of people using the method, saving a whole lot of time.


4) {P}K^-1


5) Asymmetric algorithms are good for not having to string together encryptions (like with symmetric algorithms), however they take a good bit to produce (large prime numbers)




Lecture 49
1) Yes, as long as the private key is kept secret?


2) The product of two large primes is hard to factor.


3) Yes, but it would take a long time. Brute force is the only method really.


4) {M}K is currently encrypted with the public key, but the private key is needed to decrypt it.


5) Because the encryption key is public, so anyone could have encrypted it.


6) Only one person can encrypt a file with the private encryption.


7) they must be the holder of the private key for B


8) { { M } Kb^-1 } Ka would be encrypted for A with the public key, but also encrypted by B with the private key.




Lecture 50
1) Because it is useful for comparisons, and any extranneous data is wasted


2) a weak collision is defined by finding a second input where the same hash value from one function’s output of a certain input is calculated


3) a strong collision is where you find any two different messages that output the same result via one hash function


4) preimage is where it’s hard to find value A such that the hash’d calculation of value B equals value A.


5) second preimage is where you have a value A and hash it, and you can find a value B such that when you hash it, their calculated values are the same.


6) Because you only get a small value to verify that the data has not been changed, and sometimes the actual message is completely decoded and available. (geared at integrity)


7) If M is ever tampered with, H(M)’s value should change (second preimage resistant)


8) Send a hash value encrypted with the private key including the message for the hash value, and encrypt it with their public key for them to decrypt.




Lecture 51
1) No, because it requires the private key for R


2) No, because anybody can then decrypt the outside part (while only S could have encrypted it)


3) Yes, because anyone could have encrypted the file with the public S key.


4) Confidentiality and authentication




Lecture 52
1) Nothing, they could not decode the messages without g^b mod p


2) They would still need to find b


3) They would still need to find a


for 2 and 3, if a and b are large enough, then it would take far too long to calculate the shared secret still.