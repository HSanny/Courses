Name: Jeff Upton
EID: jau55
CS Login: jupton
Email: jeffupt@gmail.com

Lecture 17
==========

1. No, a covert channel can exist in a BLP-compliant system. The channel would allow high level subjects to send information to low level subjects.

2. (A) (B) (no arrows, because neither dominates the other)

3. Yes, because any BLP system can be written as an NI policy and we've shown that covert channels can exist in BLP systems.

4. A could be (High: {Nuclear}) and B could be (Low: {Nuclear})


Lecture 18
==========

1. NI policies specify the end goal (no interference from high to lower) rather than a specific mechanism to achieve that goal.

2. It should be exactly the same as the sequence with all of the actions from h removed.

3. The number of permutations/interleavings for every possible interaction is too large in realistic systems. There are many interferences in real systems, and some of those are benign.


Lecture 19
==========

1. Integrity is especially important in commercial contexts. In the newspaper example loss of integrity can mean the end of the business.

2. The company or individual may believe that the commercial software has more integrity due to the presence of some industry standard certification.

3. Separation of duty means that several different subjects must be involved to complete a critical function, whereas sepration of function specifies that a single
subject can't have complementary roles within a critical function.

4. Auditing is necessary to support recoverability and accountability of actions in the system.

5. Separation of development and production code and data is an essential integrity concern in commercial software.

6. A transfer of funds between two bank accounts.


Lecture 20
==========

1. The New York Times reporting the movie times is highly reliable but of little sensitivity. Conversely, the National Enquirer reporting the location of Osama Bin Laden is low integrity but great sensitivity.

2. In the first row, an expert in the area of physics obviously has more integrity than a student of physics. In the second row, neither dominates the other as the expert in physics does not know anything about art. In the last row, the student of art dominates the novice with no areas of expertise.

3. H -> L

4. They are unrelated. It is possible for something to be of high integrity but low confidentiality and vice versa.


Lecture 21
==========

1. Because the results are the opposite of the BLP model with respect to the dominates relationship. In the ACM, Rs are replaced with Ws and Ws are replaced with Rs. 

2. The spot is empty because neither the subject or the object dominate the other. 

3. No, the subject must satisfy both integrity and confidentiality constraints.


Lecture 22
==========
 
1. The assumption is that the subjects are not trustworthy and are incapable of filtering low integrity information.

2. No, they are not trusted.

3. The ring policy assumes that the subjects are capable of reading low integrity information without tainting themselves.

4. They are considered more trustworthy than in LWM, but they are still not allowed to write up in integrity.


Lecture 23
==========

1. They are somewhat related, SD is a confidentiality category while ID is an integrity category.

2. Objects must be able to move from development to production (label change). Downgrade provides that mechanism as there is no obvious way using BLP and Biba alone.

3. No, they dominate confidentiality and thus cannot write.

4. Weak tranquility - objects can change levels as long as they don't violate the spirit of the secure system.


Lecture 24
==========
 
1. To establish rules that maintain consistency among the various components of the system.

2. Bank accounts and checks.

3. Candy in the bank candy bowl.

4. Certification rules look at the state of the system and state whether or not it is valid, while enforcement rules are checks that must be followed to maintain a consistent state.

5. Withdrawal from an account. (eg. (Teller, Withdrawal, {Account #1234}))


Lecture 25
==========

1. They might have some confidential information about American Airlines that could leak to United Airlines.

2. Yes, because GM and Microsoft are in different conflict classes.

3. Only GM and Microsoft, and all of the banking institutions.

4. The authorization changes dynamically depending on the history of a user's access.


Lecture 26
==========

1. It makes the security of the system much easier to manager when they are thousands of users in a small set of roles.

2. Authorized roles are the set of roles that a user is allowed to have, while active roles are the roles that a user is currently in.

3. Role authorization verifies that the user's active role is one that the user is authorized to have. Transaction authorization verifies that the transaction is authorized for one of the user's active roles.

4. RBAC is more flexible, easy to administer and custom tailored to an organization. In addition, it recognizes that subjects change roles without having to change identities.


Lecture 27
==========

1. For a system with thousands of subjects and objects, it is likely that most subjects don't have access to most objects. This results in a very large and sparse ACM.

2. ACL, Capability-based-system, rules to execute to determine availability on the fly.


Lecture 28
==========

1. The sender and the receiver must have agreed on an encoding scheme.

2. We can quantify the information that could flow through a covert channel in order to analyze the risk.

3. The receiver must know how to interpret the messages.

4. To maximize the throughput of information in the system. With limited bandwidth, the messages should be as small as possible.

5. One bit will still be needed if the receiver doesn't know when the question is answered.


Lecture 29
==========

1. n-bit binary number = n bits of information
   single decimal digit = 4 bits of information (need 10 unique values)
   two digital decimal number =7 bits of information (need 100 unique values)
   "The attack is at dawn" = depends on the uncertainty
 
2. It depends on what the receiver is trying to learn from the message. If the attack could have come at any time or any day then more information would be required - the number of unique messages goes up.

3. 4 bits of information are required to transmit exactly 16 messages because that gives 2^4=16 unique values.

4. 2^8=256, so 8 bits

5. In many realistic scenarios, we don't know the total possible number of unique messages and thus are unable to devise a perfectly efficient encoding.


Lecture 30
==========

1. When bit stands for "binary digit" it denotes a discrete quantity, when we refer to "bit" in the context of information content it is a continuous quantity.

2. 000, 001, 010, 011, 100, 101, 110, 111

3. For the 995 messages that denote success, we send 1 bit each. For the remaining 5, each message takes 5 bits. To add them up we get 995 + (5*5).

4. We can optimize the messages with higher probabilities to require fewer bits.

5. 0001, 0010, 0100, 1000

6. You can maximize the amount of information sent for a specific language.


Lecture 31
==========

1. 2846248

2. 0, 01, 001, 0001, 00001, 00001

3. Uncertainty will still remain of the message is able to be decoded into multiple interpretations.

4. Because it is the only way that the receiver is able to reassemble the exact message that was sent by the sender.

5. Morse code doesn't satisfy our criteria because it isn't a streaming encoding - there are breaks between each message.


Lecture 32
==========

1. log(8) = 3

2. -[(4/5)log(4/5) + (1/5)log(1/5)]

3. It allows you to put a lower bound on the number of bits (on average) that can be transmitted per symbol. It provides a base from which the efficiency of a particular encoding can be measured.


Lecture 33
==========

1. Simple probability. You multiply the chance of each individual outcome to get the chance of the aggregate outcome. For example HH would be expected to appear 9 times in 16 2flips.

2. The total number of expected bits is 27 bits (the sum the number of bits of each symbol * the number of times that symbol with occur). 

3. 000, 001, 010, 011, 100, 101

4.
P(1) = 6/20
P(2) = 6/20
P(3) = 3/20
P(4) = 3/20
P(5) = 1/20
P(6) = 1/20

h = -[ (6/20)log(6/20) + (6/20)log(6/20) + (3/20)log(3/20) + (3/20)log(3/20) + (1/20)log(1/20) + (1/20)log(1/20) ]

5. 
1 = 0
2 = 10
3 = 110
4 = 1110
5 = 11110
6 = 11111

6. On average it takes:
(6 * 1) + (6 * 2) + (3 * 3) + (3 * 4) + (1 * 5) + (1 * 5) = 49/20 = 2.45 bits per symbol

The naive encoding takes 3 bits per symbol.




