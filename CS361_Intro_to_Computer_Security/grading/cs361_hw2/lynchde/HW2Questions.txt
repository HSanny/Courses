Lecture 17
1. The BLP model doesn't necessarily comply with non-interference, because, as we showed in the prior module, a covert channel can still exist within a system that has successfully implemented the BLP model, and when that happens, a high-level subject can still "interfere" with a low-level subject.
2. The NI policy for a BLP system with these two subjects is that neither of these two subjects are allowed to interfere with each other, since neither of them could dominate the other. 
3. Covert channels shouldn't be able to exist in a properly implemented NI policy, but they probably do, because they are subject to the same implementation mechanisms that are used for an MLS system.  The clearest example of this is the covert channel that was shown in the prior module.
4.  This policy shows A being able to interfere with B, and that would mean that A is writing up, which would mean that A would have a clearance level that's lower than or equal to the level of B, and a group of categories that is a subset of the categories contained in B.
Lecture 18
1.  NI policies resemble metapolicies more than policies because they give a very broad goal without specifying anything about the implementation or the rules for implementation.
2. If a NI policy is correctly implemented, the view would be l1,l2,l3...lk.
3.  NI is difficult to prove for real systems because it would require a model that was very low level to capture all the possible interferences that could go on in an actual system, and even then it would have to be a very simple system or it would capture all the benign interferences that are shared by most systems with basic functionalities.
Lecture 19
1. Integrity is important in any situation where the values of sensitive data could be manipulated in a harmful way.  The example that the lecture video kept returning to was a situation at a bank, but from the perspective of a computational environment, it could be any write of a system value that is used in another operation.  If the integrity of that value is incorrect, then the resulting operations could be incorrect.
2. I think this relates to the newspaper example that was given in the video.  Theoretically, there should be more resources at a large software company to allow a team to redundantly check commercial data for security issues.
3. Separation of duty means that any critical function should require the involvement of more than one subject, and separation of function means that a subject can't be responsible for complementary functions in a critical process.
4. Auditing is important because it provides the potential for a breach of integrity to be accounted for and recovered from.
5. Lipner's integrity concerns are largely focused around separation of function, and making sure that there's little opportunity for subjects to potentially collude.
6. A common scenario where integrity would be more important than confidentiality would be a result from a race.  Obviously, participating in a race is a public display, but the integrity of the result could be valuable to the participants and observers.
Lecture 20
1. Examples of information that is highly reliable with little sensitivity is simple arithmetic that's given by math professors, and a word's definition provided by a dictionary.  Examples of information that isn't highly reliable, with greater sensitivity would be a disgruntled former employee's testimony against a former employer, and every college freshman's verbally self-reported SAT scores after they've had 2 drinks.
2. In row 1, the level is higher, and the categories of the first column is a superset of the categories in the second column.  In row 2, the level is lower for the first column versus the second column.  In row 3, the level is higher for the first column, and the set of categories in the first column is a superset of the set of categories in the second column.
3. The NI policy for the integrity metapolicy is that no subject should be able to write above the level of it's reliability.  We don't want information to flow up in integrity.
4. It means that they're totally unrelated to each other, and every feasible combination of them is a potentially valid combination. 
Lecture 21
1.  It's called the dual of the BLP model because you don't want low flowing to high in this model, and in the BLP, you don't want information flowing from high levels to lower levels, so all the dominates relationships with regards to reads and writes are reversed.  
2.  The ACM entry for Sub3-Obj3 is empty because there isn't a dominates relationship between the subject and the object.  Neither the subject or the object dominate each other because neither of their sets of categories are super sets of the other.
3.  No.  Since they are orthogonal issues, satisfying one set of constraints isn't sufficient to access an object.
Lecture 22
1.  The assumption about subjects in Biba's low water mark policy is that exposure to low quality information damages the quality of the subject that's exposed to low quality information, and their state drops accordingly.
2. The subjects aren't considered trustworthy in Biba's model, because it's assumed that anything they read is going to contaminate them, and they aren't trusted to be able to distinguish good information from bad information.
3. The assumption that the Ring policy makes is that subjects will be able to distinguish good information from bad information, and filter that information for themselves.  They're allowed to read anything.
4. The subjects are considered more trustworthy in this model than in any other Biba model, because it's assumed that they'll be able to distinguish what information is good and what information is bad.
Lecture 23
1. The SD category is defined as programs under development, and the ID category is defined as development, but since they are concerned with confidentiality and integrity, which are orthogonal issues, they aren't really related to each other.
2. If they didn't have the ability to downgrade, then software could never be moved from development into production.
3. System controllers are given a confidentiality level of SL for categories SP and SD, and they're given an integrity level of ISP for categories IP and ID.  Their confidentiality levels are dominated by development code and test data, and their integrity levels have a dominates relationship with development code/test data, so they can modify it.
4. Weak tranquility is the only form of tranquility that allows levels to change, so it's the underlying justification for the downgrade ability.
Lecture 24
1. The purpose of the four fundamental concerns of Clark and Wilson are authentication, audit, wel-formed transactions, and separation of duty. 
2. Possible examples of CDIs in a commercial setting like a bank include bank balances and checks.
3. Possible examples of UDIs in a commercial setting like a bank include candy in the bowl on the bank counter and probably something like deposit slips.
4. Certification rules and enforcement rules have a similar relationship as metapolicies and policies.  The certification rules are often general goals and the enforcement rules include more specific ways to achieve those goals.  Additionally, certification has to do with guaranteeing that an objects current state is secure, and enforcement has to do with executing an action, and then determining that the new state is secure. 
5. An example of a permission in a commercial setting is (Bank Teller, Bank Withdrawal, {Bank Balance changes <$300}).
Lecture 25
1. A consultant hired by AA potentially represents a breach of confidentiality if hired by UA because they are both competeting with each other and share conflict classes.
2. Yes, because they aren't within the same conflict classes.
3. The simplesecurity rule states that a person can't access information from companies in the same conflict class as other companies from which it has accessed information, so, in the previous example, a person who'd accessed GM's files and MSFT's files could no longer access another car maker's files, or the files of any other business who is also in whatever business we want to say MSFT is in now (OSs, Security, Research, Consulting?).
4. The chinese wall policies don't really appear to say much about what can be read and written within the conflict classes, but they give indications about what can be read and written within company classes.  The only labels involve company classes and there aren't any levels. 
Lecture 26
1. Some benefits to associating permissions with roles instead of subjects are that it's easier to administer within an organization, and it allows user to cleanly shift between roles.
2. The difference between authorized roles and active roles is that a subject can have many authorized roles that they are allowed to take, but only one active role in which they're currently occupying.
3. The difference between role authorization and transaction authorization is that a subject needs to get role authorization in order to be able to execute the transaction authorizations that are associated with that role.
4. Some of the disadvantages of standard access control policies when compared to RBAC are that the ability to switch roles requires an extra layer of rules or monitoring to ensure that obvious security breaches aren't made, such as a teller switching into an auditing role in a bank, and it could require a much more expansive group of security policies if there are many roles whose operational capabilities need to be defined.
Lecture 27
1. Nobody would want to build an explicit ACM for an access control system because it would be a very sparse matrix, since most subjects don't have access to most objects.
2. The ACM alternative for storing permissions with objects is an access control list.  If they're being store with the subjects, it's known as a capability based system.  If permissions are computed on the fly, then it's a rule based system like BLP which lets us store it implicitly.
Lecture 28
1. For the reciever to interpret the answer to a "yes" or "no" question it must know the encoding methodology that the sender is using.
2. Quantifying the information content of a message would be useful if we wanted to determine how much information can possibly be transmitted over a channel in any given time frame and to determine the scope of information that we can transmit (what kind of information it is).
3. A sender and receiver have to have some shared knowledge and an agreed encoding scheme because otherwise they'll never understand the information that they are exchanging with each other.
4. A sender wouldn't want to transmit more data than the receiver needs to resolve uncertainty because additional information will occupy space on a channel and also leaves the possibility of confusing the reciever.
5. If the receiver knows the answer to a question will be "yes", then it needs zero bits to quantify the information content, because, as long as it already knows the answer, it doesn't need a message.
Lecture 29
1. Message 1: n bits  Message 2: 4 bits Message 3:7 bits
2. The information depends on the receiver's level of uncertainty, because we aren't sure what the reciever views as possible times for the attack could be.  As the video pointed out, if there are only 2 possible times for the attack (dawn and dusk) then only one bit is necessary, but if the attack could come at any point during the next 30 days, even that message spelled out in ascii is still ambiguous. 
3.  4 bits of information have to be used to send one of 16 messages, because that is how many bits it takes to represent the number 16, and the sender and reciever could have assigned a value to each of the messages. 
4. There could be an infinite amount of information contained in the space of 256 messages.  This question could be interpreted attempting to measure the amount of information from an agreed upon message list, but one of the messages could be instructions to read a message and loop until it reads it again.
5. Very few circumstances are ideal for sending information content because very few senders and recievers would be able to create a functional communication system where they could agree on every message that could possibly need to be sent before they began communicating.  If they could, then every additional digit could reduce the search space by half.
Lecture 30
1. The two connotations of the term bit can be a binary digit or a continuous quantity of information that's composed of discrete 0's and 1's that measures the information content.  
2. The naive encoding for 8 possible messages is a binary numbering from 1-8, or 000,001,010,011,100,101,110,111.
3. The reason why the encoding takes 995 +(5*5) bits is because it can represent the most likely situation with a single bit, but with less likely situations there needs to be an indication that it's an atypical situation, and then an encoding for each error message.
4. Knowing the prior probabilities of messages can lead to a more efficient encoding because we can assign high density information like the 0 (which translates to "OK") in the example with a smaller number of bits than other messages.
5. An encoding for 4 possible messages that is worse than the naive encoding is an ascii message that says "one", "two", "three", "look at this wildly inefficient message".
6. If it's possible to find an optimal encoding it means that we can identify and utilize an optimal encoding when we're sending messages and gain efficiencies from communicating in this fashion.
Lecture 31
1. A string in the language of positive, even numbers is "2468". 
2. If an encoding is prefix free, it means that the encoding for any symbol isn't the prefix for any other symbol, so an example of a non-prefix free encoding for the possible rolls of a 6 sided die is, for 1-6 respectively, (000, 001, 010,011,100,000101).
3. It's necessary for an encoding to be uniquely decodable because, if it wasn't uniquely decodable, there would be ambiguity in the language, and it could be interpreted in multiple ways.
4. A lossless encoding scheme is desirable because otherwise the information contained in the message will gradually decay with each transmission.
5. Morse code doesn't satisfy our criteria for encodings because it's not streaming, which means that there's a break between each letter.
Lecture 32
1. The probability of landing on any side any individual roll of an 8 sided die is .125, and the log(base2) of that is -.375.  (8x-.375)x-1 is 3, which is the entropy of the language.
2. If the coin lands on a tail 4 times for every one time that it lands on a head, the probability of it landing on tails is .8, and the probability of it landing on heads is .2.  When we plug these probabilities into the formula, we get an entropy of .7219. 
3. Knowing the entropy of a language is important because knowing it can let you know how efficiently your language can possibly be encoded.
Lecture 33
1. The reasoning behind the expectations presented in slide 3 is gotten by simply multiplying the likelyhood of the stated outcome.  Since we know heads should come up 3/4ths of the time, and we know T's should come up 1/4th of the time, we can multiply those two fractions for each of the possible results and get that results probability. 
2. The total expected number of bits is 27 because on an average 16 flips, we're going to need 27 bits to send the results.
3. The naive encoding for the language in slide 5 is (000,001,010,011,100,101) for each of the respective 6 sides of the die.
4. The entropy of this language is based on the probabilities .3,.3,.15,.15,.05,.05 respectively.  These are gotten because we know that, in 20 rolls, 5 and 6 will come up once each, 3 and 4 will come up 3 times each (they're 3x as likely) and 1 and 2 will come up 6 times each (they're 2x as likely as 3 and 4).  We can plug these numbers into the equation and find that the entropy is 2.2955. 
5. An encoding that's more efficient than the naive encoding of this language is (0,10,110,1110,11110,11111)
6. It's more efficient than the naive encoding because it can take advantage of how much more often the numbers 5 and 6 come up. 