Name:  Christopher Metcalf		
EID:  csm2556	
CS Login:  cmetcalf	
Email:  csmetcalf@gmail.com

Lecture 66:
1.  PGP, or Pretty Good Privacy, uses is a general purpose encryption
algorithm that is processor independent and easy to use.  It uses the best
available cryptographic algorithms as building blocks and integrates them into
a general purpose algorithm.  It is freely available onlin, and has five basic
funtions: authentication, confidentiality, compression, email compatibility,
and segmentation.  

2. Paul Zimmerman developed PGP because he has a strong distrust of the
government and believed everyone had an absolute right of privacy.  His system
is extremely strong, using state of the art cryptographic algorithms and is
easy to use.

3.  PGP does provide extremely strong security.  It is based on algorithms
with extensive public review and has wide applicability with a standardized
scheme for encryption that supports secure communication over the internet. It
is also not developed or controlled by any government.

4.  Someone might purchase support if they did not have the time or expertise
to verify the freeware.  By going to a trusted vendor, that vendor is an added
verification, through its reputation, that the software can be trusted to do
what it is designed to do and has not been compromised.

Lecture 67: 
1.  For the authentication protocol, the sender creates a message M and then
generates a hash of M.  The sender signs the hash with his private key and
prepends the result to the message.  The receiver uses the sender's public key
to verify the sender's signature and recover the hash code.  R then generates
a new hash code for M and compares it with the hash code.  There is no
confidentiality here as the message is sent in the clear.

2.  For the confidentiality protocol, the sender generates a message M and a
random session key K.  M is encrypted using K, and K is encryped with the
recipient's public key and prepended to M.  The receiver uses his public key
to recover the session key, and the session key is used to recover M. It takes
less time for decryption by using K to encrypt the M vs. using R's public key.
This gives you the advantage of symmetric key decryption's speed if M is long. 

3.  To get both authentication and confidentiality, you would first apply the
authentication step to the original message and then apply the confidentiality
step to the resulting message.  

Lecture 68:
1. In addition to authentication and confidentiality, PGP supplies
compression, email compatibility, and segmentation.

2.  Compression is done using the ZIP compression algo, after applying the
signature and before encryption.  This is done to save bandwidth.  It is
preferable to sign the uncompressed message so that the signature does not
depend on the compression algo. 

3.  You would sign a message and then compress so than the signature does not
depend on the compression algorithm.  Encryption after compression strengthens
the encryption since compression reduces redundancy in the message.

4.  Radix-64 conversion is used to map groups of 3 octets into 7 ASCII
characters, and appends a CRC for data error checking.  This is necessary because
encrypted text contains arbitrary 8 bit octets, and many email systems would
choke on certain bit strings they'd interpret as control commands.  Radix
takes 24 bits and turns into 4 ASCII characters.  This makes sure there are no
anomolous characters in the M by doing a transformation.  You don't have to
worry about arbitrary binary strings, and every mailer can handle ASCII. 

5.  Some mailers restrict message length, so longer messages must be broken
into segments which are mailed separately.  PGP automatically segments
messages that are too large, which is done after all the other steps including
Radix 64 conversion.  So it puts the header and tail on, and breaks into
pieces that the mailer can handle, and reassembles on the receiving end.  The
signature and the key only appear once. 

Lecture 69:
1.  PGP has four types of keys:  one time session symmetric keys, public keys,
private keys, and passphrase based symmetric keys (used to protect private
keys).

2.  Each session key is symmetric, associated with a single message, used once
once, and is a randomly generated bit string. 

3.  Key size depends on the chosen algo, such as CAST 128 or 3DES.  The encryption algo
is used to generate a new n-bit key from a previous session key and two n/2
blocks generated based on user keystrokes, including keystroke timing.  The
two blocks are encrypted using the E algo and the previous key and combined to
form the new key.  It is high entropy - random appearing and not guessable. 

4.  Assuming RSA for PGP asymmetric encryption, an odd number n of sufficient
size (greater than 200 bits) is generated and tested for primality.  If it
isn't prime, then you repeat with another randomly generated number until a
prime is found.  Since we exclude even numbers, to find a prime of 200 bits
takes about ln(2^200)/2 tries.  This is performed rather infrequently.

5.  Private keys are stored encrypted with a user supplied passphrase.  The
user selects a passphrase for encrypting private keys.  When a new
public/private key pair is generated, the system asks for a new passphrase.
Using SHA-1 a 160 bit hash code is generated from the passphrase, which is
discarded.  The private key is encrypted using CAST-128 with 128 bits of the
hash code as key, and the key is discarded. The user must supply the
passphrase whenever the user wants to access the private key.   Since the
security of the system depends on protecting the private keys, these are
encrypted using a passphrase system.

Lecture 70: 
1.  The best solution is to generate an id likely to be unique for a given
user, using the least significant 64 bits of the public key as the key id. This is
used by receiver to verify that he has such a key on his key ring, and the
associated key is used for decryption.  Sending the pubic key with the message
is inefficient, and associating a unique id with each key pairing would
require all senders to know that mapping of keys to id's for all recipients. 

2.  A user's private key ring is a table of rows containing:
timestamp:  when the key pair was generated
key id:  64 least significant bits of the public key
public key: public portion of the key
private key: the private portion, encrypted with a passphrase
user id:  the users's email address

3.  A user's public key ring has the public keys of other users.  This table
of rows contains:
timestamp: when the entry was generated
key id: 64 least significant digits of this entry
public key: the public key for the entry
user id:  identifier for the owner of this key.  

You can index with the user id or the key id. 

4.  To retrieve a private key from the key ring:
- Retrieve the receiver's encrypted private key from the private key ring,
  using the key id field in the session key component of the message as an
  index
- Prompt the user for the passphrase to recover the unencrypted private key.
  The passphrase is hashed and the result is used to decrypt the private key.
- Recover the session key and decrypt the message. 

5.  The key legitimacy field is associated with each public key in the user's
public key ring, and it indicates the extent to which PGP trusts that this is
a valid public key for this user.  Legitimacy is determined from certificates
and chains of certificates. 

6.  A key is revoked when the owner issues a signed key revocation
certificate.  Recipients are expected to update their public key rings. 
       
Lecture 71: 
1.  The consumer problem is when the attacker gets logically between the
client and the service and somehow disrupts the service.  It blocks traffic
from the client.  The producer problem is when the attacker produces so many
services that the server is overwhelmed.  It disadvantages the server by
filling it up by sending illegitimate requests. 

2.  A TCP handshake occurs in 3 steps.  First, the server receives the SYN
packet and allocates space in an internal table.  Then, it sends a
SYN/Acknowledgement back to the caller.  The connection remains half open
until the ACK is received by the server or times out.   Syn flooding occurs
when an attacker forges the return address on a number of syn packets.  The
servers fills the table with these half open connections, and sits and waits
for the ACK to be returned.  All legitimage requests are denied until the
connections time out.  

3.  Increasing the server's queue size doesn't work because it would consume
resources, plus the attacker can always send more requests. 
Shortening the time out period would disadvantage slower clients and would
itself be the equivalent of a DOS attack. 
Filtering suspicious packets by discarding the packet if the return address
does not match the apparent source is difficult.  This is hard to determine
lookding at the RA, and you may throw away legitimate packets. 

Lecture 72: 
1.  A filter can detect patterns of identifiers in the request stream and
block messages in that pattern. It checks if a packet is malicious.  Ingress
filtering sniffs incoming packets and discards those with source IP addresses
outside a given range (those unreachable via that interface).  It is diffult
to distinguish attack packets from regular packets in standard usage. 

2.  Intrusion detection systems focus on detecting attacks already past the
firewall.  They analyze traffic patterns and react to anomalous patterns.
Intrusion prevention systems attempts to prevent attacks by blocking attempted
attacks.  They try to make sure an attack never gets in.  This assumes
attacking traffic can be identified. 

3.  Four solutions are:
Over provisioning the networks:  Have too many servers to be overwhelmed.
This is very expensive and unworkable. 
Filtering attack packets:  Distinguish attack packets from regular packets
(may be difficult)
Slowing down processing:  Disadvantages all attackers, but disproportionately
the attackers.
Speak up solution:  Request additional info from all requestors.  This assumes
attacker's bots are maxed out, and raises the proportion of valid to invalid
requests. 

Lecture 73: 
1. False negatives are when a genuine attack is not detected. So it is an
attack and not flagged as one. 
False positives are when harmless behavior is mis-classified as an attack.
Which is worse depends on what you need to protect and how sensitive you are
to attack.  If you are protecting nuclear secrets, you don't want false
negatives.  

2.  Accurate is if it detects all genuine attacks (no false negatives).
Precise is if it never reports legitimate behavior as an attack (no false
positives).  

3.  If everything is classified is an attack, it will be accurate (no false
negatives).  If nothing is classified as an attack, it will be precise (no
false positives).  

4.  The base rate fallacy is a fallacy that most IDS's suffer from.  For
example, if only 1% traffic are actual attacks, and the IDS classifies an
attack with prob 90%, it will classify a valid connection as an attack with
prob 10%.  This means although 90% sounds great, it is a fallacy.  Actually,
there is a 92% chance that a raised alarm is false.  

Lecture 74:
1.  Code Red Version I did the following:
-If the date is between the 1st and 19th of the month, it generated a random
list of IP addresses and attempted to infect those machines.
-On the 20th to 28th of the month, it launched a DoS flooding attack on
whitehouse.gov.
-It also defaces some webpages with the words "Hacked by Chinese".

2.  It was ineffective because:
-It used a static seed in its random number generator so every instance of the
worm generated the same list of machines to attack, so a limited number of
machines were affected.  Because of this, the worm spread slowly.
-The IP address of whitehouse.gov was changed so the DoS attack failed.  

3.  Code Red I was memory resident, meaning it resided in the volatile memory
of the machine.  Because of this, the machine can be disinfected by simply
rebooting it.

4.  Code Red II was more effective because it used a random seed in the random
number generator.  Thus, infected machines would generate different list of IP
addresses to attack. 

Lecture 75:  
1.  Code Red II was identical to Code Red I using the same vulnerability except
that version 2 used a random seed in the random number generator, and then applies a mask to produce
an address to probe.  Version 2 also neither defaces web pages nor launched a
DoS attack, nor was it memory resident.

2.  It incorporated its elaborate propogation scheme to maximize the number of
computers infected.  Computers using the same prefix were likely on the same
subnet, and machines on the subnet likely run the same software and are easier
to infect.  So the scheme was designed to infect as many machines as possible
quickly and easily.

3.  Code Red II installs a mechanism for remote, root level access to in the
infected machine.  This backdoor allows any code to be executed, so the
machine could be used as zombies for future attacks.

4.  A large population of unpatched machines shows that people don't fix their
machines, and that a large number of machines remain vulnerable to the same or
similar attack. 

5.  This Verizon observation shows that people are remiss at patching their
machines, and that makes the internet more vulnerable. 

Lecture 76: 
1. A certification regime for secure products is necessary because most
customers don't have the expertise to perform the necessary steps to evaluate
the buying process for a product.  So a standardized process of independent
evaluation by expert teams that provides a certified level of confidence for a
security product is useful in the customers' buying process (assessing needs
to determine requirements, helping id the right product to meet those
requirements, and deploying that product).

2.  An evaluation standard should provide:
- a set of requirements defining security functionality (requirement for OS is
  different than for firewall)
- a set of assurance requirements needed for establishing the functional
  requirements (what is the policy for various kinds of things).
- a methodology for determining that the functional requirements are met
- a grade - a measure of evaluation result indicating the trustworthiness of
  the evaluated system.  
 
3.  Crypto devices are designed for the protection of sensitive but
unclassified info.  The separate evaluation mechanism is because federal
agencies are required to use products either approved by NSA or validated by
FIPS 140-1 or -2.  The government agency needs an approved list according to
grade, and devices are a separate category than just a software crypto
solution, as they also involve hardware. 

4.  The four levels of certification for crypto devices are:
Level 1:  basic security with at least one approved algo or function
Level 2:  improved physical security, tamper evident packaging
Level 3:  strong tamper resistance and countermeasures
Level 4:  complete envelope of protection including immediate zeroing of keys
upone tampering. 

Level 1 is basically for the home and the government uses Level 4.    

Lecture 77:
1.  The Commone Criteria is a set of documents and a methodology that
standardizes secure systems evaluation criteria, and is used by some 26
countries. 

2.  It is called the Common Criteria because evaluations, up to Level 4 usually,
by one signing country are respected by all the others.  This saves time and
expense in obtaining security grading for products to be offered in many
different countries, and essentially standardizes the criteria across borders.

3.  National Schemes are country specific evaluation methodologies that
countries may need to see for their unique circumstances, applying some
additional rigor, and maybe only by specified labs licensed by that
government.  

4.  A protection profile is a set of implementation independent security
requirements for a category of products. It is a set of documents describing a
security policy for a class of systems.  So it is a description of a family of
products in terms of threats, security objectives, and requirements of the
Common Criteria.  Examples include firewalls and operating systems.
The security target is document that contains the set of security requirements 
of an actual product (the target of evaluation)to be evaluated, and specifies 
the measures offered by that product to meet those requirements. It is
evidence that your artifact meets its security policy.  

Lecture 78: 
1.  The overall goal of the protection profile is to describe what security
means for a particular class of systems.  With WBIS, it is lists assets,
environmental assumptions, threats, organizational security policies, security
objectives (eg. detect invalid tags) and security requirements.  If you charge
by weight, you don't want someone to subvert the accuracy of that weight with
a faulty signal. 

2.  The purpose of the various parts of the protection profile, listing
assets, environmental assumptions, threats, organizational security policies, security
objectives (eg. detect invalid tags) and security requirements, is to describe
what security means for a particular class of systems.  It lists in broad
terms the class of mechanisms you need to worry about. It isn't concerned with
the actual mechanisms of a particular system.   

3.  This is a mapping of threats/assumptions to security
objectives/requirements.  It is a systematic way to see whether
threats/assumptions are being addressed by mechanisms that you would propose. 
All threats should have a corresponding mechanism to solve the problems presented. 

Lecture 79:
1. The overall goal of the security target evaluation is to evaluate a
particular product how it enforces a notion of security, which is typically
detailed by a protection profile.  So, it lists security objectives for the
TOE and the environments, assumptions, and threats. It then tells how the
system counters those threats and guaranteess that assumptions are satisfied.  
Here, Sun is arguing that their solution implements the policy as specified. 

2. A protection profile is a description in broad terms of what security means
for a class of systems.  There is no particular product being evaluated. 
A security target evaluation specifies what security means for this particular
product and how this product enforces that notion of security. So, it is an
evaluation of how a particular solution implements the policy as specified.    

Lecture 80: 
1.  An EAL defines the care with which the product was developed and the rigor 
of the evaluation process.  EAL's are evaluation grades that reflect a specified level 
of rigor.  They show how much evidence was put forward.  The grade means that your evidence is
adequate to that level.  
EAL 1: Functionally tested
2: Structurally tested
3: methodologically tested and checked
4: methodologically designed, tested, and reviewed
5: semiformally designed and tested
6: semiformally verified design and tested
7: formally verified design and tested

2. A CC certificate means that the government of the country where it was
performed believes the evaluation was done properly. It indicates a good faith
effort to ensure the product meets the vendor claims.  Tests are done by an
independent organization accredited to perform CC testing, which is certified
by NIST if in the US. They can test up to EAL4, with the NSA doing EAL 5-7. 

3.  Higher EALs are not mutually recognized by various countries because with
highly sensitive data, each country does not want to rely on a guarantee from
some other foreign power.  That foreign power could have possibly planted a
backdoor in the software for spying.   

4.  Vendors cannot certify their own product as that would subvert the purpose
of the ratings.  They may be willing, in the interest of profit, to cut
corners and give themselves a higher rating for marketing purposes.  With an
independent lab, there is a greater likelihood that common testing procedures
are followed and there is on undue influence, so the ratings can be trusted. 

5.  This is a tough one.  I suppose that you want to formally test the code
through a proof, and not just by reverse engineering the model.  

Thanks!
      


