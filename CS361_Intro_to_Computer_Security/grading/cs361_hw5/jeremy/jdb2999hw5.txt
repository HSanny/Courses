Name: Jeremy Bouzigard
EID: jdb2999
CS Login: jeremy
Email: jbouzigard@gmail.com

CS361 Questions Week 5

--------------------

Lecture 66

1. PGP (Pretty Good Privacy) is a data encryption and decryption program designed to take the best algorithms and package them in a way that can be easily used by the average person. 

2. The development of PGP was motivated by Zimmerman's strong distrust of government and belief that everyone has an absolute right to privacy.

3. Yes, because it uses strong cryptographic algorithms as its building blocks, such as RSA and Diffie-Hellman.

4. Because many companies do not use freeware and prefer having a commercial entity that they can call on for support.

--------------------

Lecture 67

1. Sender creates a message. Sender hashes the message. Sender encrypts the hash code with RSA using the Sender's private key and the result is prepended to the mesage. Receiver decrypts the encrypted hash code with Sender's public key. Receiver generates a new hash of the message and compares it with decrypted hash code.

2. Sender creates a message and generates a random session key. Sender uses symmetric encryption to encrypt the message with the session key. Sender encrypts the session key using RSA with the receiver's public key and prepends it to the message. Receiver uses receiver's private key to decrypt and recover the session key. Receiver decrypts the message with the session key.

3. The protocols for each are combined. Sender generates a signature for the plaintext message and prepends it to the message. The plaintext message plus signature is encrypted. The session key is encrypted using RSA and prepended to the message.

--------------------

Lecture 68

1. Besides authentication and confidentiality, PGP also offers compression, email compatability, and segmentation and reassembly.

2. Compression is needed to save bandwidth because these messages are typically sent across the Internet. Messages can be arbitrarily long, so compression is useful to save bandwith.

3. A message is signed and then compressed rather than the other way around so that the signature does not depend on the compression algorithm.

4. Radix-64 conversion takes a standard set of three octets and turns it into four ASCII characters (3 bytes into 4 bytes). The result is that everything in the message is an ASCII character, which can be handled b every mailer in the world. This is needed so that message does not end up containing arbitrary binary strings that are interpreted differently from system to system.

5. Segmentation is needed to handle messages that are too large. By breaking the message into pieces that are known to be an appropriate size, the message will not be too long for any mailer along the way.

--------------------

Lecture 69

1. PGP uses session keys (used once and generated for each new message) for symmetric encryption, public keys and private keys for use in asymmetric encryption, and passphrase-based keys used to storae private keys. 

2. The session key must be randomly generated and must be the appropriate length depending on the encryption algorithm. They must be high entropy (random appearing) and not guessable.

3. A previous session key is used to encrypt a newly generated key based on keystrokes (inlcuding keystroke timing) to form a new key.

4. A very large number of the appropriate size is generated and tested for primality. This is repeated until a prime is generated. This is expensive operation but performed relatively infrequently.

5. Private keys are stored in an encrypted form. The keys used to encrypt the private key are the passphrase-based keys. Whenever the system has to store/access a private key, the user has to type in a passphrase. That passphrase is then hashed to generate a fixed length bit string, which is used as encryption or decryption for the private key. This process is necessary so that an attacker cannot access a private key simply by gaining access to a user's files or hard disk.

--------------------

Lecture 70

1. PGP generates an ID for the pair that is likely to be unique to a given user. That ID is the least significant 64-bits of the public key as the ID.

2. A user's private key ring contains their own private keys and information to identify them. This includes a timestamp (when the key was generated), a key ID (64 least significant digits of the public key), the public key (the public portion of the key), the private key (the private portion, ecnrypted using a passphrase), and user ID (usually the user's email address, may differ with key pairs).

3. A user's public key ring contains the public keys of other users. This includes a timestamp (when the entry was generated), key ID (64 least significant digits of this public key), the public key (public key for entry), and user ID (identifier for the owner of this key).

4. Whenever PGP must use a private key, it must decrypt it. PGP retrieves the receiver's encrypted private key from the private key ring using the key ID field in the session key component of the message as an index. PGP then prompts the user for the passphrase to recover the unencrypted private key. PGP uses the passphrase to recover the session key and decrypt the message.

5. The key legitimacy field indicates the extent to which PGP trusts that this is a valid public key for this user. Legitimacy is determined from certificates and chains of certificates, the user's assessment of the trust to be assigned to the key, and other various heuristics.

6. The owner of that key issues a signed key revocation certificate and recipients are expected to update their public key rings.

--------------------

Lecture 71

1. The consumer problem refers to when the attacker gets logically between the client and service and somehow disrupts the communication. The producer problem is when someone directly attacks the server by producing, offering, or requesting so many services that the server is overwhelmed. The producer problem is far more prevalent.

2. SYN flooding happens when an attacker forges the return address on a number of SYN packets. The server fills its table with these half-open connections and waits for the appropriate response. Eventually this times out, but in the meanwhile, the half-open connections fill up the server's table. If there are enough of them, there are not room for legitimate clients to make a TCP connection.

3. Increasing the server's queue size is not ideal because each of these half-open connections takes ~600 bytes, so it consumes considerable resources and the atacker could just send more requests. Shortening the time-out period is not ideal because slower clients may be disadvantaged because they time out before completing the handshake. Filtering suspicious packets is not ideal because it is difficult to know when a packet is legitimate.

--------------------

Lecture 72

1. Packet filtering works well to prevent attacks because the attacks never have a chance to come through, but it is difficult to discriminate patterns of attack from patterns of standard usage.

2. An intrusion detection system analyzes traffic patterns within the system and tries to identify anomalous patterns. An intrusion prevention system attempts to prevent intrusions by more aggresively blocking attempted attacks. IDS assumes attack is hardly within the walls, while IPS tries to make sure the attack never gets in at all.

3. Over-provisioning the network means to have too many servers to be overwhelmed, but this is expensive and unworkable. Filtering attack packets means to somehow distinguish the attack packets from regular packets, but this may not be possible. Slow down processing disadvantages all requestors, including legitimate clients. "Speak up" solution means to request additional packets from all requestors because those attacking are probably already maxed out, but legitimate customers can ramp up activity and increase the percentage of legitimate traffic.

--------------------

Lecture 73

1. In an IDS system, false positives are when harmless behavior is mis-classified as an attack; false negatives are when a genuine attack is not detected. Which is worse varies with the system and scenario.

2. "Accurate" means the IDS system detects all legitimate attacks and has no false negatives. "Precise" means the IDS system never reports legitimate behavior as an attack.

3. It is simple to design a system that reports all traffic as an attack or all traffic as not an attack, but the goal of an IDS system is to find the appropriate middle ground.

4. The base rate fallacy means that if attacks are relatively rare, you need a very high degree of accuracy for the system to be useful. This is relevant to IDS because on a typical system lots of packets are coming in, but not many are malicious. Since the possibility of an attack is statistically rare, you need a very high degree of accuracy to prevent many false alarms.

--------------------

Lecture 74

1. CodeRed version 1: Between the 1st and the 19th of the month, the attack generated a random list of IP addresses and attempted to infect those machines. On the 20th to 28th of the month, the attack attempted to launch a DoS flooding attack on whitehouse.gov. The worm also defaced some webpages.

2. The random number generator used a static seed, meaning it always started from the same position and every instance of the worm generated the same list of IP addresses, so a limited number of machines were actually attacked. Each infected machine probed the same list of machines, sot he worm spread slowly. It was also determined fairly early the attack was going to be on whitehouse.gov, so they changed the IP address.

3. A worm is "memory resident" if it resides in the volatile memory of the machine. The implication is that to get it off a machine, all you need to do is reboot; on the flip side, you were likely to be affected again.

4. CodeRed version 2 was much more effective than version 1 because it corrected many of version 1's flaws. In particular, version 2 used a random seed in the random number generator, so the worm was spread much more widely. It also wreaked havoc on the Internet because many IP addresses generated did not corespond to computers, but other things like modems and routers.

--------------------

Lecture 75

1. CodeRedII is not clearly actually related to CodeRedI at all, other than the writer clearly knew about CodeRedI because the string "CodeRed" was in the code.

2. CodeRedII incorporated an elaborate propogation scheme to spread itself to as many computers as possible, specifically targeted at computers rather than things like modems or routers.

3. CodeRedII did not attempt to deface web pages or launch a DoS attack. However, it installed a mechanism for remote, root-level access to the infected machine. This backdoor allows any code to be executed, so the machines could be used as zombies for future attacks.

4. If there is a huge population of unpatched machines, the worms can continue circulating and possibly cause damage even after a patch is developed.

5. The lesson of the study is that users do not often patch their machines. The result is that the Internet is a very vulnerable place because a large percentage of machines are susceptible to attack, long after a patch is released.

--------------------

Lecture 76

1. A certification regime for secure products is necessary and useful because most customers do not have the expertise to perform an evaluation, but they still would like to have a level of confidence in security products.

2. A set of requirements defining security functionality gives the goal of security for a particular system, a set of assurance requirements needed for establishing the functional requirements gives the policy for various kinds of categories, a methodology for determining that functional requirements is useful for applying the evaluation, and a measurement of the evaluation result indicating the trustworthiness of the evaluated system is useful to known the overall result/grade.

3. Crypto devices have a separate evaluation mechanism because cryptology is a particularly sensitive area and there are not as many experts in the field as in other areas.

4. Level 1 achieves basic security with at least one approved algorithm or function, useful for home devices; Level 2 offers improved physical security including tamper-evident packaging; Level 3 offers strong tamper-resistance and countermeasures; and Level 4 offers a complete envelope of protection including immediate zeroing of keys upon tampering. The lower levels are more likely to be used in home settings, while the higher levels are often used by the government.

--------------------

Lecture 77

1. The Common Criteria is a set of documents and methodology for applying a criteria for secure systems evaluations used by many countries and respected by all who have adopted it. 

2. The Common Criteria is "common" to the approximately 26 countries that have adopted it.

3. "National Schemes" may be needed because even though the overall goals of security are common among all countries, there are also likely smaller individual needs specific to each country.

4. A protection profile (policies) is a formal description of security for a class of systems, while a security target (products) is a specific system or family of systems that can be evaluated against a protection profile.

--------------------

Lecture 78

1. The overall goal of the protection profile as exemplified by the WBIS example is to define what security means for a particular class of systems (in this case, waste  disposal).

2. The purpose of the various parts of the protection profile is to define security for a class of systems. For instance, it is used to identify the assets, assumptions, threats, organizational security policies, security objectives, security requirements. It does not say what particular mechanisms are in a particular system (there isn't one), but what general class of mechanisms you need to worry about for systems of this type; the security requirements are therefore broad.

3. The matrix is a mapping of threats / assumptions to security objectives / requirements. On the left are threats/assumptions, across top are security objectives and requirements for any system that is actually built. The idea is that if you fill in the matrix with a security objective/requirement designed to counter a threat or fulfill an objective and every row in the table somewhere has an 'X', then all threats have some mechanism to counter them and all assumptions are validated by an assumption. This gives a systematic way to determine whether the mechanisms that are being proposed are adequate to solve the problems that are presented.

--------------------

Lecture 79

1. The overall goal of the security target evaluation as exemplified by the Sun Identity Manager example is to specify what security means for this product and how the product enforces that notion of security, all of which is judged by some certifying atuhority.

2. A protection profile (policies) evaluations defines what security means for a particular class of systems (in this case, waste  disposal), while a security target evaluation specifies what security means to a specific system and how the product enforces that notion of security.

--------------------

Lecture 80

1. EALs (Evaluation Assurance Level) refers to how much evidence an applicant puts forward that the evaluation will succeed. EAL1 is functionally tested, for instance, and implements the security policy with minimal evidence. As you go up in level, more and more detailed evidence is provided that there is a correspondence between the artifact and the policy.

2. The Common Criteria evaluations at higher levels are performed by the government of the country where the evaluation is performed. In the US, only NSA does testing for level 5 and above. At the lower levels, evaluations are done by commercial laboratories that are certified by the government (NIST).

3. The higher EALs are not necessarily mutually recognized by various countries possibly because the evidence and proofs presented at the higher levels are more specialized and sensitive, so a government likely would only want to put faith in those that it has looked at itself.

4. Vendors cannot certify their own products. This is because their is a clear conflict-of-interest in a product vendor self-certifying.

5. It is a bad idea to reverse engineer the model from the code because you are fitting the model to fit the code, not fitting the model to fit the specific problem at hand. This results in likely a less convincing and more convoluted model.