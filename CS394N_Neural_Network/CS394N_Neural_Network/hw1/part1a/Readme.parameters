Description of the parameters in the simulation file (e.g. 1dsimu, 2dsimu):

---------------------------------------------------------------------------
## The size of the graphics output (low-left, upper-right corner).
## Screen coordinates vary within [0 1]
0.0 0.0 1.0 1.0		;;; left,low,right,high

## Dimensions of the feature map network; here it is a linear array of
##   50 units.
50 1 			;;; nx, ny

## disp_rate: how often the graphics display is updated. For example, if
## you want to see the state of the network every 5 iterations, set this
## to 5.
## seed: random number generator seed (no need to change it).
5 1 			;;; disp_rate, seed

## The next few lines contain the parameters you have to tune to get
##   the map to self-organize properly: 
## tend: number of training presentations (time-end).
## nphase: number of training phases (described below).
## nc_[-1]: initial neighborhood radius. Units whose x and y coordinates are
##  within this distance of the winning unit are modified.
##  Initially the neighborhood should cover almost the whole network, and 
##  then gradually decrease to 0.
## alpha_[-1]: initial learning rate (at time 0). Should also gradually
##  decrease to 0.
1000 4 40 0.1		;;; tend, nphase, nc_[-1], alpha_[-1]

## Parameters describing each training phase:
## t_[phase]: end time of the phase.
## nc_[phase]: neighborhood radius at the end of the phase. During the phase,
##   the neighborhood is decreased from nc_[phase-1] to nc_[phase]
##   in discrete steps approximating linear decrease. It reaches the value
##   nc_[phase] at time t_[phase].
## alpha_[phase]: learning rate at the end of the phase. Also decreases
##   linearly during the phase.
100 20 0.05		;;; t_[phase], nc_[phase],alpha_[phase]
500 1 0.05		;;; t_[phase], nc_[phase],alpha_[phase]
750 0 0.05		;;; t_[phase], nc_[phase],alpha_[phase]
1000 0 0.05		;;; t_[phase], nc_[phase],alpha_[phase]

## Times when snapshots are saved. Below, only one snapshot at the end
##   of the simulation at t=1000 is saved. 999999999 is just a sentinel
##   ending the list of snapshot times. E.g., if you want to save a
##   snapshot at the beginning, and at times 100 500 and 1000, you would say
##   -1 100 500 1000 999999999
1000 999999999 	;;; snapshots (epoch):0=initial, 9x9=last

## snapshots are stored here, below the list of snapshot times...
---------------------------------------------------------------------------

For example, if you want to first train the net for 500 iterations in
the background, check how it is doing, and then continue until t=1000,
this is what you would do:

1. Specify tend=500, disp_rate=0, snapshots = -1 100 500 1000
2. nohup nice sofm(hp) 1dsimu &
   ( the network is trained for 500 presentations, and the state of the
     net is stored in the beginning, at t=100 and in the end. )
3. Change disp_rate=1
4. sofmhp 1dsimu
   ( now each snapshot is displayed on the screen. Hit return to get
     the next snapshot. )
5. Change tend=1000, disp_rate=0
6. nohup nice sofm(hp) 1dsimu &
   ( the simulation is continued from the last stored snapshot, and run
     until tend )
7. Do 3. and 4. again to view the results.

Of course, you can train the network on screen (with disp_rate=1), and
that is probably a good thing to do when you first try to get a feel of
the self-organizing process. Later, with larger networks, the training
takes longer and you want to turn the graphics off and only look at the
snapshots.
