<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <title>Part 3b Readme</title>
    <meta http-equiv="content-type" content="text/html; charset=iso-8859-1">
  </head>
  <body>

<h2>Part 3b Readme</h2>

<p>
In this part you will refine the map using the LVQ1 algorithm. We will
use LVQ1 instead of LVQ2, LVQ2.1 or LVQ3 because if you trained the map
well, all the units are already good representations of your training
samples, and it is unlikely that any inputs fall in the training window
(which is around the midpoint between the weight vectors of the winner
and the runner-up).

<ol>
<li> Copy your simulation file (e.g., <tt>mysimu</tt>), the vector file, and
  the label file (e.g., <tt>train.vectors</tt> and <tt>train.labels</tt>) from
  part2 to your part3b directory. 
<li>Prepare your simulation file. (As you recall, that file was the same as the
  one from part2 except for having only a single snapshot in it). Change the
  iteration number of the single snapshot in the new mysimu file to "0".
  The phase, epoch,and alpha definitions in the file will be used by LVQ1
  (in step 4, below) to train the network with the same vectorfile and
  labelfile, continuing from the weights specified in the snapshot. (Note
  that the neighborhood parameters do not have any meaning in LVQ, but
  we'll leave them in anyway so that the file format is compatible with
  the other programs.)  An example of a starting file is in <a href="simu.demo.orig">simu.demo.orig</a>,
  which is identical to the 
  <a href="../part3a/simu.demo">simu.demo</a> file from part3a except that 
  the iteration number is zero.  A copy of <a href="trainingvectorfile.demo">
  trainingvectorfile</a> and <a href="traininglabelfile.demo">
  traininglabelfile</a> are also provided in this directory as examples.
  
<li> Edit <tt>sofm.tcl</tt> so that it uses your simulation file (mysimu). 
<li>Type <tt>./sofm.tcl</tt>. Press STEP to load the network from part 2 and 
  then press TRAIN.  Again, it is often best to 
  train with <tt>disp_rate</tt> set to 0, and saving snapshots occasionally. 
  After training is finished, quit the program and then 
  change <tt>disp_rate</tt> to 1 and type <tt>./sofm.tcl</tt> again; the 
  program will display the organization at each snapshot and also some 
  performance data on the training set.  Alternatively, if your machine is
  fast enough that running in the background is less important than just not
  having so much text output, you could just set <tt>disp_rate</tt> to some
  reasonably large value (e.g. 25) so that it only displays a few pictures
  over the course of the training.  Note that it is often difficult to see any 
  change between the output for different iterations, since the training set 
  performance will already be at 100% typically.  When this step is completed,
  the mysimu file should have one or more new snapshots (at iterations 
  specified in the mysimu parameters) added to the end of the file.
  
<li> After you are happy with the training, remove all but the last
snapshot, and use the program in part3a to test your final network
with the testvectors (<a href="simu.demo">simu.demo</a> is an example of the
final file, with only a single LVQ-enhanced snapshot remaining).  Did LVQ 
training improve the classification performance? (It should, of course; 
however, whether you see a difference or not depends on the training set. 
Some people may see a large improvement, others none at all.)
</ol>

<hr>
<p>Updated by Leif Johnson.</p>
<p>Originally by Marshall Mayberry.</p>

  </body>
</html>
